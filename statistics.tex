% !TEX root = prop.tex
\section{Aim 4: A Statistical Action Suggestion Semantics}
\label{sec:statistics}
\Hazel will provide suggestions to help the programmer finish incomplete
programs by providing a \emph{suggestion palette}, marked \textbf{(d)} in
Figure~\ref{fig:hazel-mockup}.  This palette will suggest semantically
relevant code  
snippets when the cursor is on an empty hole. It will also suggest other relevant
edit actions, including high-level edit actions implemented by imported action
macros (e.g. the refactoring action in Figure~\ref{fig:hazel-mockup}.)  When the
cursor is on a non-empty hole, indicating a static error, it will suggest
bug fixes. We plan to also consider bugs that do not correspond to static
errors, including those identified explicitly by the programmer, and those
related to assertion failures or exceptions encountered when using the live
programming features of \HazelEnv. In these situations, we plan to defer to
existing automated fault localization techniques~\citep{Jones02,
  Qi13issta,Renieris03}.

Note that features like these are not themselves novel. Many editors provide
contextually relevant suggestions. Indeed, code inference and suggestion is
closely related to several major research areas: code
completion~\citep{Muslu12icse-nier,icse-naturalness12}, program
synthesis~\citep{Gulwani2010}, and program
repair~\citep{legoues12tse,angelix,prophet,Ke15ase}.  

The problems that existing systems encounter is exactly the problem we have 
been discussing throughout this proposal: when attempting to integrate these 
features into an editor, it is difficult to reason about malformed or meaningless
edit states. As such, many of these systems use tokenized representations of programs \citep{icse-naturalness12}. Because \HazelEnv maintains the invariant that every
edit state is a syntactically and semantically meaningful formal structure, we can develop a
more principled solution to the problem of generating meaningful suggestions. In particular,
we will \emph{prove} that every action suggestion generated for a particular edit state is 
meaningful for that edit state.

In addition to investigating the problem of populating the suggestion palette
with semantically valid actions, we will consider the problem of evaluating
the statistical likelihood of the suggestions. This
requires developing a statistical model over actions.  We will prove that this statistical model is a
proper statistical distribution (e.g. that it ``integrates'' to 1), and that it
assigns zero probability to semantically invalid actions. Collectively, we refer 
to these contributions as a \emph{statistical action suggestion semantics}. 

\paragraph{Action suggestion generation.}  Syntax guided program synthesis uses
syntactic rules to constrain code generation with respect to a
specification~\citep{sygus} and provides a natural starting point for
code generation in \Hazel. PI Le Goues has had recent success exploring its use
for semantically-informed program repair in unannotated C
programs~\citep{sygus-icsme-era}, developing a translation between value-based
specifications and a generic input language for various syntax-guided synthesis
engines.  The connection between code generation for incomplete programs in \Hazel
and generic program repair is natural: In both, we must reason over a partial
program to infer or synthesize replacement code.  Here, we propose to develop a
similar automated translation approach that makes use both of known
dynamic values (adapting the value-based specification approach from the repair
work) and of the semantics around a cursor to inform synthesis. We speculate
that Hazel's semantics will scalably restrict the synthesis search space, while
decreasing the technique's reliance on test suite behavior.  Incorporating
semantic information as well as runtime values in suggestion generation mitigates the
risk of overfitting to existing test suites~\citep{Qi13issta,Smith15fse}, as we
have shown for other types of semantic reasoning in the context of program repair~\citep{Ke15ase}.


\begin{figure}
\small
\fbox{$\hGamma \vdash P(\hexp \Leftarrow \htau | \texttt{var})$}
\begin{mathpar}
\inferrule{\hexp \neq x}{
	\hGamma \vdash P(\hexp \Leftarrow \htau | \texttt{var}) = 0
}

\inferrule{x \notin \text{dom}(\hGamma)}{
	\hGamma \vdash P(\hexp \Leftarrow \htau | \texttt{var}) = 0
}

\inferrule{
	x : \htau' \in \hGamma\\
	\tincompat{\htau}{\htau'}
}{
	\hGamma \vdash P(x \Leftarrow \htau | \texttt{var}) = 0
}

\inferrule{
	x : \htau \in \hGamma\\
	(\hGamma_{\htau} = \{ x | x : \htau' \in \hGamma \wedge \tcompat{\htau}{\htau'} \} )
}{
	\hGamma \vdash P(x \Leftarrow \htau | \texttt{var}) = \frac{1}{|\hGamma_{\htau}|}
	% \hGamma \vdash P(x \Leftarrow \htau | \phi = \texttt{var}) = \dfrac{1}{|\hGamma_\htau|}
}
\end{mathpar}
% \begin{tabular}{c|c}
% Joint probability & Conditional Probability \\
% $P(\Gamma \vdash e \Rightarrow \tau | \phi_d ) = p$  % joint probability
%  &
% $ P (\Gamma ; \vdash e \Mapsfrom \tau ; \phi_d ) = p )$ 
% \\
% $\inferrule{ x \notin dom(\Gamma) }
% { P (\Gamma \vdash x \Rightarrow \tau | var_d ) = 0 }
% $
% &
% $\inferrule{ x \notin dom(\Gamma) }
% { P (\Gamma \vdash x \Mapsfrom \tau | var_d ) = 0 }$
%  \\
% $
% \inferrule { x : \tau' \in \Gamma \qquad \tau \neq \tau' }
% {P(\Gamma \vdash x \Rightarrow \tau | var_d ) = 0 }$
% &
% $\inferrule { x : \tau' \in \Gamma \qquad \tau \neq \tau' }
% {P(\Gamma \vdash x \Mapsfrom \tau | var_d ) = 0 }$
%  \\
% $\inferrule{  
% x : \tau \in \Gamma }
% { P (\Gamma \vdash x \Rightarrow \tau | var_d ) = \dfrac{1}{|\Gamma|}}$
% &
% $\inferrule{  
% x : \tau \in \Gamma \qquad (\Gamma_{\tau} = \{ x | x' : \tau \in \Gamma \} )}
% { P (\Gamma \vdash x \Mapsfrom \tau | var_d ) = \dfrac{1}{|\Gamma_\tau|}}$
% \end{tabular}
\caption{A variable likelihood calculus.}
\label{fig:likelihood-calculus}
\end{figure}

\paragraph{Evaluating the statistical likelihood of an action.}
As preliminary work in preparation for this proposal, we begin by considering a
very limited case: evaluating the likelihood of suggestions that construct a  variable when the cursor is in analytic position. The rules given in
Figure~\ref{fig:likelihood-calculus} determine how to compute the relevant
quantity: $\hGamma \vdash P(\hexp \Leftarrow \htau \vert 
\texttt{var})$. The first three rules assign zero probability to the case where
(1) $\hexp$ is not in fact a variable; (2) $\hexp$ is a variable that is not in
the context; (3) $\hexp$ is a variable in context of a type that is inconsistent
with $\htau$. The final rule assigns non-zero probability to the situation where
$\hexp=x$ and the context assigns $x$ a type consistent with $\htau$. It does
not prefer any one such variable over another, so the probability distribution
in this case is uniform over all such variables. 
It is easy to see that this distribution ``integrates'' to one. It is also easy
to see that any expressions assigned non-zero probability are well-typed in the
given context.


\paragraph{Proposed Research.} We plan to formalize and integrate various
syntax- and type-directed techniques for suggestion generation into \HazelEnv's
action suggestion semantics. Initially, these will be fairly simple: the
suggestions will inspect the context, and the structure of the expected type. As
we proceed, we will incorporate more sophisticated techniques, drawing from the
related work and approaches referenced above.

In parallel, we will develop more sophisticated variations of the likelihood
calculus sketched above. To estimate the likelihood of variables, we might use
other statically tracked covariates, e.g. the distance to the binding of $x$,
information about whether a variable has already been used, or even linguistic
features of the variable identifier, to assign non-uniform probabilities. We
will also define likelihood models for the other forms of expressions.  

The preliminary work above considered only expressions in analytic position,
i.e. where the type is known. This corresponds to a \emph{conditional
  distribution}. In synthetic position, the type is also a random variable. This
corresponds to a \emph{joint distribution}. As such, we need to develop models
that estimate the likelihood of types as well.

In some of these cases, the models will need to learn parameters from a corpus
of code. For example, to estimate the likelihood of a constructor for a labeled
sum type, we will need to estimate how often each constructor is used in
code. We plan to describe the estimation techniques abstractly, and prove that
they are unbiased formally, as well as learn and evaluate them empirically over code or edit
history corpora.  Existing work demonstrates that token-level models of code can
often be sufficiently
expressive~\citep{buggy-naturalness-icse16,icse-naturalness12}. However, we
anticipate that our models may benefit from additional learned context at a
higher level of representation, such as expressed as
trees~\citep{changedistiller,probabilistic-cfgs}.  The research challenge lies in
scalably and expressively integrating static context into these
representations. We will use initial pilot studies with 
\HazelEnv to gather concrete estimates. We will also investigate the possibility
of testing these models on languages similar to \HazelEnv for which there
already exist large program corpora, e.g. OCaml.

